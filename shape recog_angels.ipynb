{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"shape recog/angels.ipynb","provenance":[],"authorship_tag":"ABX9TyMhYCRgUBZc0W2DsxQCzIol"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"cb7HkJgvxisy","colab_type":"code","colab":{}},"source":["!pwd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8AXgRsKBJ7m8","colab_type":"text"},"source":[" Figures from EOG to figure converter will be imperfect and vague.Such figures are recognised using this classifier using deep learning"]},{"cell_type":"markdown","metadata":{"id":"3wfYoy4papT2","colab_type":"text"},"source":["Importing reqired files from github"]},{"cell_type":"code","metadata":{"id":"SRRQ8QK-xysP","colab_type":"code","colab":{}},"source":["!git clone https://github.com/keyurr2/shape-classifier-cnn.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aKqmYuUvzquV","colab_type":"code","colab":{}},"source":["!pwd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e_w13kCf0Hta","colab_type":"code","colab":{}},"source":["cd /content/shape-classifier-cnn/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YX73oWkZ0agP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598545986516,"user_tz":-330,"elapsed":1534,"user":{"displayName":"AMULYA RAJAGOPAL","photoUrl":"","userId":"14295027553975742220"}},"outputId":"2016e073-df56-47ae-fd12-afdc3766bfda"},"source":["cd /content/shape-classifier-cnn/shapes-dataset-practice/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/shape-classifier-cnn/shapes-dataset-practice\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MSRTf-rw1c_V","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598545988448,"user_tz":-330,"elapsed":914,"user":{"displayName":"AMULYA RAJAGOPAL","photoUrl":"","userId":"14295027553975742220"}},"outputId":"ba24913c-a8bd-497d-eaef-55e073cb1f0f"},"source":["!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["circle\tsquare\tstar  triangle\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J7qNMx9Q4YkL","colab_type":"code","colab":{}},"source":["cd /content/shape-classifier-cnn/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aRpAcIPm5Qgc","colab_type":"code","colab":{}},"source":[" !pip install -r requirements.txt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3I_PdOPcbEu_","colab_type":"text"},"source":["Running framework and training data"]},{"cell_type":"code","metadata":{"id":"Igzq7vBb5rpc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598546127960,"user_tz":-330,"elapsed":34228,"user":{"displayName":"AMULYA RAJAGOPAL","photoUrl":"","userId":"14295027553975742220"}},"outputId":"1efd9351-6760-4856-c080-5b0ebcdcdc18"},"source":["! python cnn.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","cnn.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), input_shape=(28, 28, 3..., activation=\"relu\")`\n","  16, 3, 3, input_shape=(28, 28, 3), activation='relu'))\n","cnn.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n","  classifier.add(Convolution2D(32, 3, 3, activation='relu'))\n","Found 300 images belonging to 3 classes.\n","Found 90 images belonging to 3 classes.\n","Epoch 1/25\n","2020-08-27 16:34:55.374473: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","300/300 [==============================] - 1s 5ms/step - loss: 1.1033 - acc: 0.3133 - val_loss: 1.0986 - val_acc: 0.3333\n","Epoch 2/25\n","300/300 [==============================] - 1s 4ms/step - loss: 1.1004 - acc: 0.3100 - val_loss: 1.0975 - val_acc: 0.3667\n","Epoch 3/25\n","300/300 [==============================] - 1s 4ms/step - loss: 1.0988 - acc: 0.3933 - val_loss: 1.0604 - val_acc: 0.5444\n","Epoch 4/25\n","300/300 [==============================] - 1s 4ms/step - loss: 1.0397 - acc: 0.4567 - val_loss: 0.9557 - val_acc: 0.5889\n","Epoch 5/25\n","300/300 [==============================] - 1s 4ms/step - loss: 0.9535 - acc: 0.5867 - val_loss: 0.8390 - val_acc: 0.6000\n","Epoch 6/25\n","300/300 [==============================] - 1s 4ms/step - loss: 0.8062 - acc: 0.6233 - val_loss: 0.5753 - val_acc: 0.7556\n","Epoch 7/25\n","300/300 [==============================] - 1s 4ms/step - loss: 0.5910 - acc: 0.7700 - val_loss: 0.4005 - val_acc: 0.8778\n","Epoch 8/25\n","300/300 [==============================] - 1s 4ms/step - loss: 0.5143 - acc: 0.7867 - val_loss: 0.2969 - val_acc: 0.9111\n","Epoch 9/25\n","300/300 [==============================] - 1s 4ms/step - loss: 0.3767 - acc: 0.8600 - val_loss: 0.1782 - val_acc: 0.9222\n","Epoch 10/25\n","300/300 [==============================] - 1s 4ms/step - loss: 0.3337 - acc: 0.8833 - val_loss: 0.1480 - val_acc: 0.9667\n","Epoch 11/25\n","300/300 [==============================] - 1s 4ms/step - loss: 0.2557 - acc: 0.9167 - val_loss: 0.1752 - val_acc: 0.9333\n","Epoch 12/25\n","300/300 [==============================] - 1s 4ms/step - loss: 0.1921 - acc: 0.9467 - val_loss: 0.1017 - val_acc: 0.9556\n","Epoch 13/25\n","300/300 [==============================] - 1s 4ms/step - loss: 0.1581 - acc: 0.9433 - val_loss: 0.1147 - val_acc: 0.9556\n","Epoch 14/25\n","300/300 [==============================] - 1s 4ms/step - loss: 0.1561 - acc: 0.9433 - val_loss: 0.0420 - val_acc: 0.9889\n","Epoch 15/25\n","300/300 [==============================] - 1s 4ms/step - loss: 0.1685 - acc: 0.9400 - val_loss: 0.0809 - val_acc: 0.9778\n","Epoch 16/25\n","300/300 [==============================] - 1s 4ms/step - loss: 0.1580 - acc: 0.9600 - val_loss: 0.0413 - val_acc: 0.9889\n","Epoch 17/25\n","300/300 [==============================] - 1s 4ms/step - loss: 0.1123 - acc: 0.9533 - val_loss: 0.1108 - val_acc: 0.9556\n","Epoch 18/25\n","300/300 [==============================] - 1s 4ms/step - loss: 0.1281 - acc: 0.9433 - val_loss: 0.0282 - val_acc: 1.0000\n","Epoch 19/25\n","300/300 [==============================] - 1s 4ms/step - loss: 0.1568 - acc: 0.9400 - val_loss: 0.0363 - val_acc: 0.9889\n","Epoch 20/25\n","300/300 [==============================] - 1s 4ms/step - loss: 0.1169 - acc: 0.9667 - val_loss: 0.0147 - val_acc: 1.0000\n","Epoch 21/25\n","300/300 [==============================] - 1s 4ms/step - loss: 0.0685 - acc: 0.9867 - val_loss: 0.0680 - val_acc: 0.9778\n","Epoch 22/25\n","300/300 [==============================] - 1s 4ms/step - loss: 0.1083 - acc: 0.9633 - val_loss: 0.0161 - val_acc: 1.0000\n","Epoch 23/25\n","300/300 [==============================] - 1s 4ms/step - loss: 0.0894 - acc: 0.9733 - val_loss: 0.0351 - val_acc: 0.9889\n","Epoch 24/25\n","300/300 [==============================] - 1s 4ms/step - loss: 0.0644 - acc: 0.9767 - val_loss: 0.0186 - val_acc: 1.0000\n","Epoch 25/25\n","300/300 [==============================] - 1s 4ms/step - loss: 0.0749 - acc: 0.9667 - val_loss: 0.0064 - val_acc: 1.0000\n","/content/shape-classifier-cnn/visulization.py:16: MatplotlibDeprecationWarning: Passing the minor parameter of set_xticks() positionally is deprecated since Matplotlib 3.2; the parameter will become keyword-only two minor releases later.\n","  'acc']) + 1), len(model_history.history['acc']) / 10)\n","/content/shape-classifier-cnn/visulization.py:27: MatplotlibDeprecationWarning: Passing the minor parameter of set_xticks() positionally is deprecated since Matplotlib 3.2; the parameter will become keyword-only two minor releases later.\n","  'loss']) + 1), len(model_history.history['loss']) / 10)\n","<Figure size 1500x500 with 2 Axes>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yQDBwWO-a61j","colab_type":"text"},"source":["Running test dataset"]},{"cell_type":"code","metadata":{"id":"vr3LQXad5-LU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598546664323,"user_tz":-330,"elapsed":3850,"user":{"displayName":"AMULYA RAJAGOPAL","photoUrl":"","userId":"14295027553975742220"}},"outputId":"c490dc86-1e61-4934-e338-6f25fb6d47f9"},"source":["!python predict.py --testdata"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","2020-08-27 16:44:21.665123: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","Classify images on test dataset\n","Found 90 images belonging to 3 classes.\n","('circles/drawing(100).png', 0, 0)\n","('circles/drawing(11).png', 0, 0)\n","('circles/drawing(13).png', 0, 0)\n","('circles/drawing(15).png', 0, 0)\n","('circles/drawing(2).png', 0, 0)\n","('circles/drawing(21).png', 0, 0)\n","('circles/drawing(24).png', 0, 0)\n","('circles/drawing(30).png', 0, 0)\n","('circles/drawing(39).png', 0, 0)\n","('circles/drawing(4).png', 0, 0)\n","('circles/drawing(42).png', 0, 0)\n","('circles/drawing(43).png', 0, 0)\n","('circles/drawing(45).png', 0, 0)\n","('circles/drawing(46).png', 0, 0)\n","('circles/drawing(5).png', 0, 0)\n","('circles/drawing(54).png', 0, 0)\n","('circles/drawing(56).png', 0, 0)\n","('circles/drawing(66).png', 0, 0)\n","('circles/drawing(67).png', 0, 0)\n","('circles/drawing(69).png', 0, 0)\n","('circles/drawing(7).png', 0, 0)\n","('circles/drawing(73).png', 0, 0)\n","('circles/drawing(77).png', 0, 0)\n","('circles/drawing(8).png', 0, 0)\n","('circles/drawing(81).png', 0, 0)\n","('circles/drawing(85).png', 0, 0)\n","('circles/drawing(88).png', 0, 0)\n","('circles/drawing(89).png', 0, 0)\n","('circles/drawing(93).png', 0, 0)\n","('circles/drawing(99).png', 0, 0)\n","('squares/drawing(16).png', 1, 1)\n","('squares/drawing(20).png', 1, 1)\n","('squares/drawing(21).png', 1, 1)\n","('squares/drawing(23).png', 1, 1)\n","('squares/drawing(24).png', 1, 1)\n","('squares/drawing(28).png', 1, 1)\n","('squares/drawing(4).png', 1, 1)\n","('squares/drawing(41).png', 1, 1)\n","('squares/drawing(44).png', 1, 1)\n","('squares/drawing(47).png', 1, 1)\n","('squares/drawing(50).png', 1, 1)\n","('squares/drawing(53).png', 1, 1)\n","('squares/drawing(54).png', 1, 1)\n","('squares/drawing(56).png', 1, 1)\n","('squares/drawing(57).png', 1, 1)\n","('squares/drawing(6).png', 1, 1)\n","('squares/drawing(64).png', 1, 1)\n","('squares/drawing(66).png', 1, 1)\n","('squares/drawing(69).png', 1, 1)\n","('squares/drawing(75).png', 1, 1)\n","('squares/drawing(76).png', 1, 1)\n","('squares/drawing(8).png', 1, 1)\n","('squares/drawing(80).png', 1, 1)\n","('squares/drawing(81).png', 1, 1)\n","('squares/drawing(82).png', 1, 1)\n","('squares/drawing(88).png', 1, 1)\n","('squares/drawing(89).png', 1, 1)\n","('squares/drawing(92).png', 1, 1)\n","('squares/drawing(93).png', 1, 1)\n","('squares/drawing(97).png', 1, 1)\n","('triangles/drawing(1).png', 2, 2)\n","('triangles/drawing(11).png', 2, 2)\n","('triangles/drawing(12).png', 2, 2)\n","('triangles/drawing(15).png', 2, 2)\n","('triangles/drawing(16).png', 2, 2)\n","('triangles/drawing(20).png', 2, 2)\n","('triangles/drawing(21).png', 2, 2)\n","('triangles/drawing(25).png', 2, 2)\n","('triangles/drawing(26).png', 2, 2)\n","('triangles/drawing(36).png', 2, 2)\n","('triangles/drawing(38).png', 2, 2)\n","('triangles/drawing(39).png', 2, 2)\n","('triangles/drawing(42).png', 2, 2)\n","('triangles/drawing(48).png', 2, 2)\n","('triangles/drawing(51).png', 2, 2)\n","('triangles/drawing(55).png', 2, 2)\n","('triangles/drawing(63).png', 2, 2)\n","('triangles/drawing(67).png', 2, 2)\n","('triangles/drawing(7).png', 2, 2)\n","('triangles/drawing(70).png', 2, 2)\n","('triangles/drawing(73).png', 2, 2)\n","('triangles/drawing(79).png', 2, 2)\n","('triangles/drawing(8).png', 2, 2)\n","('triangles/drawing(81).png', 2, 2)\n","('triangles/drawing(86).png', 2, 2)\n","('triangles/drawing(87).png', 2, 2)\n","('triangles/drawing(89).png', 2, 2)\n","('triangles/drawing(91).png', 2, 2)\n","('triangles/drawing(92).png', 2, 2)\n","('triangles/drawing(99).png', 2, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5zRl3oNzE_FM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598536635521,"user_tz":-330,"elapsed":1034,"user":{"displayName":"AMULYA RAJAGOPAL","photoUrl":"","userId":"14295027553975742220"}},"outputId":"28e4db10-2c53-4e89-922c-04b620944fa3"},"source":[" !pwd"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/shape-classifier-cnn\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_4M0C1A3bcQq","colab_type":"text"},"source":[" Checking prediction on validation data"]},{"cell_type":"code","metadata":{"id":"rKP_uTIcShST","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598538007453,"user_tz":-330,"elapsed":4110,"user":{"displayName":"AMULYA RAJAGOPAL","photoUrl":"","userId":"14295027553975742220"}},"outputId":"642280b3-95a5-44d3-bfe5-461fde2c86f9"},"source":["!python predict.py --validationdata"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","2020-08-27 14:20:05.392535: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","Classify images on validation dataset\n","Found 90 images belonging to 3 classes.\n","('circles/drawing(100).png', 0, 0)\n","('circles/drawing(11).png', 0, 0)\n","('circles/drawing(13).png', 0, 0)\n","('circles/drawing(15).png', 0, 0)\n","('circles/drawing(2).png', 0, 0)\n","('circles/drawing(21).png', 0, 0)\n","('circles/drawing(24).png', 0, 0)\n","('circles/drawing(30).png', 0, 0)\n","('circles/drawing(39).png', 0, 0)\n","('circles/drawing(4).png', 0, 0)\n","('circles/drawing(42).png', 0, 0)\n","('circles/drawing(43).png', 0, 0)\n","('circles/drawing(45).png', 0, 0)\n","('circles/drawing(46).png', 0, 0)\n","('circles/drawing(5).png', 0, 0)\n","('circles/drawing(54).png', 0, 0)\n","('circles/drawing(56).png', 0, 0)\n","('circles/drawing(66).png', 0, 0)\n","('circles/drawing(67).png', 0, 0)\n","('circles/drawing(69).png', 0, 0)\n","('circles/drawing(7).png', 0, 0)\n","('circles/drawing(73).png', 0, 0)\n","('circles/drawing(77).png', 0, 0)\n","('circles/drawing(8).png', 0, 2)\n","('circles/drawing(81).png', 0, 0)\n","('circles/drawing(85).png', 0, 0)\n","('circles/drawing(88).png', 0, 0)\n","('circles/drawing(89).png', 0, 0)\n","('circles/drawing(93).png', 0, 0)\n","('circles/drawing(99).png', 0, 0)\n","('squares/drawing(16).png', 1, 1)\n","('squares/drawing(20).png', 1, 1)\n","('squares/drawing(21).png', 1, 1)\n","('squares/drawing(23).png', 1, 0)\n","('squares/drawing(24).png', 1, 0)\n","('squares/drawing(28).png', 1, 2)\n","('squares/drawing(4).png', 1, 1)\n","('squares/drawing(41).png', 1, 1)\n","('squares/drawing(44).png', 1, 1)\n","('squares/drawing(47).png', 1, 1)\n","('squares/drawing(50).png', 1, 1)\n","('squares/drawing(53).png', 1, 1)\n","('squares/drawing(54).png', 1, 1)\n","('squares/drawing(56).png', 1, 1)\n","('squares/drawing(57).png', 1, 1)\n","('squares/drawing(6).png', 1, 1)\n","('squares/drawing(64).png', 1, 1)\n","('squares/drawing(66).png', 1, 1)\n","('squares/drawing(69).png', 1, 1)\n","('squares/drawing(75).png', 1, 1)\n","('squares/drawing(76).png', 1, 1)\n","('squares/drawing(8).png', 1, 1)\n","('squares/drawing(80).png', 1, 1)\n","('squares/drawing(81).png', 1, 0)\n","('squares/drawing(82).png', 1, 1)\n","('squares/drawing(88).png', 1, 1)\n","('squares/drawing(89).png', 1, 1)\n","('squares/drawing(92).png', 1, 1)\n","('squares/drawing(93).png', 1, 1)\n","('squares/drawing(97).png', 1, 1)\n","('triangles/drawing(1).png', 2, 2)\n","('triangles/drawing(11).png', 2, 2)\n","('triangles/drawing(12).png', 2, 2)\n","('triangles/drawing(15).png', 2, 2)\n","('triangles/drawing(16).png', 2, 2)\n","('triangles/drawing(20).png', 2, 2)\n","('triangles/drawing(21).png', 2, 2)\n","('triangles/drawing(25).png', 2, 2)\n","('triangles/drawing(26).png', 2, 2)\n","('triangles/drawing(36).png', 2, 2)\n","('triangles/drawing(38).png', 2, 2)\n","('triangles/drawing(39).png', 2, 2)\n","('triangles/drawing(42).png', 2, 2)\n","('triangles/drawing(48).png', 2, 2)\n","('triangles/drawing(51).png', 2, 2)\n","('triangles/drawing(55).png', 2, 2)\n","('triangles/drawing(63).png', 2, 2)\n","('triangles/drawing(67).png', 2, 2)\n","('triangles/drawing(7).png', 2, 2)\n","('triangles/drawing(70).png', 2, 2)\n","('triangles/drawing(73).png', 2, 2)\n","('triangles/drawing(79).png', 2, 2)\n","('triangles/drawing(8).png', 2, 2)\n","('triangles/drawing(81).png', 2, 2)\n","('triangles/drawing(86).png', 2, 2)\n","('triangles/drawing(87).png', 2, 2)\n","('triangles/drawing(89).png', 2, 2)\n","('triangles/drawing(91).png', 2, 2)\n","('triangles/drawing(92).png', 2, 2)\n","('triangles/drawing(99).png', 2, 2)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RvcNuOLgbk87","colab_type":"text"},"source":["Predicting on our data/scanned output of imperfect shape figures from eyeball movement detector and configuring correct shape"]},{"cell_type":"code","metadata":{"id":"_yGNpPYmwO20","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"status":"ok","timestamp":1598546694956,"user_tz":-330,"elapsed":3671,"user":{"displayName":"AMULYA RAJAGOPAL","photoUrl":"","userId":"14295027553975742220"}},"outputId":"60c3b802-6de8-46bb-c185-47366b5a8450"},"source":["!python predict.py --image /content/drawing.png "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","2020-08-27 16:44:52.465877: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","\n","And /content/drawing.png is the Circle\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yZkNSekBx2kw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"status":"ok","timestamp":1598547545114,"user_tz":-330,"elapsed":4114,"user":{"displayName":"AMULYA RAJAGOPAL","photoUrl":"","userId":"14295027553975742220"}},"outputId":"ed0bab32-d031-45b7-ead8-01fc2effe4eb"},"source":["!python predict.py --image /content/IMG_20200827_221935.jpg"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","2020-08-27 16:59:02.341338: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","\n","And /content/IMG_20200827_221935.jpg is the Triangle\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IYPLn_9ecZhM","colab_type":"text"},"source":["Testing on vague o/p circle"]},{"cell_type":"code","metadata":{"id":"ReL9WEXx3doA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"status":"ok","timestamp":1598548094924,"user_tz":-330,"elapsed":4324,"user":{"displayName":"AMULYA RAJAGOPAL","photoUrl":"","userId":"14295027553975742220"}},"outputId":"2000e396-6606-4d9d-beb5-cb708019872b"},"source":["!python predict.py --image /content/circlee.jpg"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","2020-08-27 17:08:11.973292: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","\n","And /content/circlee.jpg is the Circle\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"quQ5_pRPcixw","colab_type":"text"},"source":["Testing on vague o/p square and triangle"]},{"cell_type":"code","metadata":{"id":"LydbKCi64hxB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"status":"ok","timestamp":1598548546781,"user_tz":-330,"elapsed":6191,"user":{"displayName":"AMULYA RAJAGOPAL","photoUrl":"","userId":"14295027553975742220"}},"outputId":"ce16fe04-ad5a-4d56-e33a-1ae2651616ba"},"source":["!python predict.py --image /content/square.jpg\n","!python predict.py --image /content/tria.jpg\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","2020-08-27 17:15:41.909000: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","\n","And /content/square.jpg is the Square\n","Using TensorFlow backend.\n","2020-08-27 17:15:44.485339: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","\n","And /content/tria.jpg is the Triangle\n"],"name":"stdout"}]}]}